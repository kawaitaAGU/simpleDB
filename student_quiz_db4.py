import streamlit as st
import pandas as pd
from datetime import datetime
import io
import re

st.set_page_config(page_title="ğŸ“˜ å­¦ç”ŸæŒ‡å°ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹", layout="wide")
st.title("ğŸ” å­¦ç”ŸæŒ‡å°ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹")

# â–¼ ã©ã“ã‹ã§ df ã‚’ä½œã£ãŸç›´å¾Œã«å¿…ãšå®Ÿè¡Œ
def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    # ç›®ã«è¦‹ãˆãªã„BOMã‚„å…¨è§’/åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã€æ”¹è¡Œãªã©ã‚’é™¤å»
    def _clean(s):
        s = str(s)
        s = s.replace("\ufeff", "")           # BOM
        s = re.sub(r"[\u3000 \t\r\n]+", "", s)  # å…¨è§’/åŠè§’ç©ºç™½ã¨æ”¹è¡Œç­‰ã‚’é™¤å»
        return s
    df = df.copy()
    df.columns = [_clean(c) for c in df.columns]

    # åˆ—åã®åˆ¥åã‚’å¸åï¼ˆå­˜åœ¨ã—ã¦ã„ã‚‹æ–¹ã‚’æ­£å¼åã«å¯„ã›ã‚‹ï¼‰
    alias_map = {
        # å•é¡Œæ–‡ã®å€™è£œ
        "å•é¡Œæ–‡": ["è¨­å•", "å•é¡Œ", "æœ¬æ–‡"],
        # é¸æŠè‚¢
        "é¸æŠè‚¢1": ["é¸æŠè‚¢ï¼¡","é¸æŠè‚¢a","A","ï½"],
        "é¸æŠè‚¢2": ["é¸æŠè‚¢ï¼¢","é¸æŠè‚¢b","B","ï½‚"],
        "é¸æŠè‚¢3": ["é¸æŠè‚¢ï¼£","é¸æŠè‚¢c","C","ï½ƒ"],
        "é¸æŠè‚¢4": ["é¸æŠè‚¢ï¼¤","é¸æŠè‚¢d","D","ï½„"],
        "é¸æŠè‚¢5": ["é¸æŠè‚¢ï¼¥","é¸æŠè‚¢e","E","ï½…"],
        # æ­£è§£
        "æ­£è§£":   ["è§£ç­”","ç­”ãˆ","ans","answer"],
        # ç§‘ç›®åˆ†é¡
        "ç§‘ç›®åˆ†é¡": ["åˆ†é¡","ç§‘ç›®","ã‚«ãƒ†ã‚´ãƒª","ã‚«ãƒ†ã‚´ãƒªãƒ¼"]
    }
    colset = set(df.columns)
    for canonical, candidates in alias_map.items():
        if canonical in colset:
            continue
        for c in candidates:
            if c in colset:
                df.rename(columns={c: canonical}, inplace=True)
                colset.add(canonical)
                break
    return df

# ä¾‹ï¼‰èª­ã¿è¾¼ã¿ç›´å¾Œã«
# df = pd.read_csv("...csv")
# df = normalize_columns(df)

# ä»¥é™ã€åˆ—ã‚¢ã‚¯ã‚»ã‚¹ã¯ .get() ã§å®‰å…¨ã«
def get_q(row):
    return row.get("å•é¡Œæ–‡", "")

def get_choice(row, i):
    return row.get(f"é¸æŠè‚¢{i}", "")

def get_ans(row):
    return row.get("æ­£è§£", "")

def get_cat(row):
    return row.get("ç§‘ç›®åˆ†é¡", "")

# ---------- ã“ã“ã‹ã‚‰ä¿å­˜ãƒœã‚¿ãƒ³å‘¨è¾ºã®å …ç‰¢åŒ– ----------
today = datetime.now().strftime("%m%d")
search = st.session_state.get("search", "")  # ã©ã“ã‹ã§å…¥åŠ›ã—ã¦ã„ã‚‹æƒ³å®š
filename_base = f"{(search or 'results')}_{today}"

# filtered_df ãŒæœªå®šç¾©/ç©ºã®ã¨ãè½ã¡ãªã„ã‚ˆã†ã«
if "filtered_df" not in locals():
    st.info("æ¤œç´¢çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
else:
    if filtered_df.empty:
        st.warning("ãƒ’ãƒƒãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        # å¿µã®ãŸã‚åˆ—ã‚’æ­£è¦åŒ–
        filtered_df = normalize_columns(filtered_df)

        # æ–‡å­—åˆ—åŒ–ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆNaNå®‰å…¨ï¼‰
        def _s(x):
            return "" if pd.isna(x) else str(x)

        # .txt ç”Ÿæˆï¼ˆè¡¨ç¤ºç”¨â†’DLãƒœã‚¿ãƒ³ï¼‰
        txt_buffer = io.StringIO()
        for _, row in filtered_df.iterrows():
            row = row.to_dict()
            txt_buffer.write(f"å•é¡Œæ–‡: {_s(get_q(row))}\n")
            for i in range(1, 6):
                v = _s(get_choice(row, i))
                if v != "":
                    txt_buffer.write(f"é¸æŠè‚¢{i}: {v}\n")
            txt_buffer.write(f"æ­£è§£: {_s(get_ans(row))}\n")
            txt_buffer.write(f"åˆ†é¡: {_s(get_cat(row))}\n")
            txt_buffer.write("-" * 40 + "\n")

        st.download_button(
            label="ğŸ“¥ ãƒ’ãƒƒãƒˆçµæœã‚’ .txt ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=txt_buffer.getvalue(),
            file_name=f"{filename_base}.txt",
            mime="text/plain"
        )

        # .csv ç”Ÿæˆï¼ˆåˆ—ãŒç„¡ã‘ã‚Œã°è¿½åŠ ã—ã¦å‡ºåŠ›ï¼‰
        out_df = filtered_df.copy()
        for c in ["å•é¡Œæ–‡","é¸æŠè‚¢1","é¸æŠè‚¢2","é¸æŠè‚¢3","é¸æŠè‚¢4","é¸æŠè‚¢5","æ­£è§£","ç§‘ç›®åˆ†é¡"]:
            if c not in out_df.columns:
                out_df[c] = ""
        csv_buffer = io.StringIO()
        out_df.to_csv(csv_buffer, index=False, encoding="utf-8-sig")
        st.download_button(
            label="ğŸ“¥ ãƒ’ãƒƒãƒˆçµæœã‚’ .csv ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv_buffer.getvalue(),
            file_name=f"{filename_base}.csv",
            mime="text/csv"
        )
